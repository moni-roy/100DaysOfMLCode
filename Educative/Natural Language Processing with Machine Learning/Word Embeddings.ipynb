{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.14-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599631208389",
   "display_name": "Python 2.7.14 64-bit ('nlp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "text_corpus = ['bob ate apples, and pears', 'fred ate apples!']\n",
    "tokenizer.fit_on_texts(text_corpus)\n",
    "new_texts = ['bob ate pears', 'fred ate pears']\n",
    "print(tokenizer.texts_to_sequences(new_texts))\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "  oov_token='OOV')\n",
    "text_corpus = ['bob ate apples, and pears', 'fred ate apples!']\n",
    "tokenizer.fit_on_texts(text_corpus)\n",
    "print(tokenizer.texts_to_sequences(['bob ate bacon']))\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=2)\n",
    "text_corpus = ['bob ate apples, and pears', 'fred ate apples!']\n",
    "tokenizer.fit_on_texts(text_corpus)\n",
    "\n",
    "# the two most common words are 'ate' and 'apples'\n",
    "# the tokenizer will filter out all other words\n",
    "# for the sentence 'bob ate pears', only 'ate' will be kept\n",
    "# since 'ate' maps to an integer ID of 1, the only value \n",
    "# in the token sequence will be 1\n",
    "print(tokenizer.texts_to_sequences(['bob ate pears']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    # Convert a list of text strings into word sequences\n",
    "    def tokenize_text_corpus(self, texts):\n",
    "        # CODE HERE\n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        return self.tokenizer.texts_to_sequences(texts)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_and_size(sequence, target_index, window_size):\n",
    "    return (sequence[target_index], window_size//2)\n",
    "\n",
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    # Convert a list of text strings into word sequences\n",
    "    def get_target_and_context(self, sequence, target_index, window_size):\n",
    "        target_word, half_window_size = get_target_and_size(\n",
    "            sequence, target_index, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_indices(sequence, target_index, half_window_size):\n",
    "    left_incl = max(0, target_index - half_window_size)\n",
    "    right_excl = min(len(sequence), target_index + half_window_size + 1)\n",
    "    return (left_incl, right_excl)\n",
    "    pass\n",
    "\n",
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    # Convert a list of text strings into word sequences\n",
    "    def get_target_and_context(self, sequence, target_index, window_size):\n",
    "        target_word, half_window_size = get_target_and_size(\n",
    "            sequence, target_index, window_size\n",
    "        )\n",
    "        left_incl, right_excl = get_window_indices(\n",
    "            sequence, target_index, half_window_size)\n",
    "        return target_word, left_incl, right_excl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    def tokenize_text_corpus(self, texts):\n",
    "        self.tokenizer.fit_on_texts(texts)\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        return sequences\n",
    "\n",
    "    # Convert a list of text strings into word sequences\n",
    "    def get_target_and_context(self, sequence, target_index, window_size):\n",
    "        target_word = sequence[target_index]\n",
    "        half_window_size = window_size // 2\n",
    "        left_incl = max(0, target_index - half_window_size)\n",
    "        right_excl = min(len(sequence), target_index + half_window_size + 1)\n",
    "        return target_word, left_incl, right_excl\n",
    "    \n",
    "    # Create (target, context) pairs for a given window size\n",
    "    def create_target_context_pairs(self, texts, window_size):\n",
    "        pairs = []\n",
    "        sequences = self.tokenize_text_corpus(texts)      \n",
    "        for sequence in sequences:\n",
    "            for i in range(len(sequence)):\n",
    "                target_word, left_incl, right_excl = self.get_target_and_context(\n",
    "                    sequence, i, window_size)\n",
    "                for ind in range(left_incl, right_excl):\n",
    "                    if ind != i:\n",
    "                        pairs.append((sequence[i], sequence[ind]))\n",
    "        return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tf.get_variable('v1', shape=(1, 3)))\n",
    "print(tf.get_variable('v2', shape=(2,), dtype=tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.random_uniform((5, 10),minval=-1,maxval=2)\n",
    "v = tf.get_variable('v1.1', initializer=init)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tensor(\"embedding_lookup/Identity:0\", shape=(2, 10), dtype=float32)\n"
    }
   ],
   "source": [
    "emb_mat = tf.get_variable('v3', shape=(5, 10))\n",
    "word_ids = tf.constant([0, 3])\n",
    "emb_vecs = tf.nn.embedding_lookup(emb_mat, word_ids)\n",
    "print(emb_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initializer(embedding_dim, vocab_size):\n",
    "    init = tf.random_uniform((vocab_size, embedding_dim),minval=-0.5/embedding_dim, maxval=0.5/embedding_dim)\n",
    "    return init\n",
    "    pass\n",
    "\n",
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    # Forward run of the embedding model to retrieve embeddings\n",
    "    def forward(self, target_ids):\n",
    "        initializer = get_initializer(\n",
    "            self.embedding_dim, self.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip-gram embedding model\n",
    "class EmbeddingModel(object):\n",
    "    # Model Initialization\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=self.vocab_size)\n",
    "\n",
    "    # Forward run of the embedding model to retrieve embeddings\n",
    "    def forward(self, target_ids):\n",
    "        initializer = get_initializer(\n",
    "            self.embedding_dim, self.vocab_size)\n",
    "        # CODE HERE\n",
    "        self.embedding_matrix = tf.get_variable('embedding_matrix', initializer=initializer)\n",
    "        embeddings = tf.nn.embedding_lookup(self.embedding_matrix, target_ids)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}